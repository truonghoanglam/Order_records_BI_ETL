{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686219c0-07f1-44f1-9c44-72d7c3c55d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83842c97-48f2-4aca-a0e6-5fa824e3aa8a",
   "metadata": {},
   "source": [
    "# Create function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a784c-a9b5-45a4-8143-f5c14b989caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'FILE', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bac3b-7511-402d-a27b-09267cc9d296",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def insert_into_table(curr, shop_id, id, status_name, status, tags, inserted_at, id_column,  updated_at, revenue, warehouse_info, status_history, \n",
    "                       partner, assigning_seller):\n",
    "    insert_into_records = (\"\"\"INSERT INTO project_1_data (shop_id, id, status_name, status, tags, inserted_at, id_column,  updated_at, revenue, warehouse_info, status_history, \n",
    "     partner, assigning_seller)\n",
    "    VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\")\n",
    "    row_to_insert = (shop_id, id, status_name, status, tags, inserted_at, id_column,  updated_at, revenue , warehouse_info, status_history, \n",
    "                      partner, assigning_seller)\n",
    "    curr.execute(insert_into_records, row_to_insert)\n",
    "\n",
    "\n",
    "def update_row(curr, shop_id, id, status_name, status, tags, inserted_at, id_column,  updated_at, revenue, warehouse_info, status_history, \n",
    "                partner, assigning_seller):\n",
    "    query = (\"\"\"UPDATE project_1_data\n",
    "            SET shop_id                 = %s,\n",
    "                id                      = %s,\n",
    "                status_name             = %s,\n",
    "                status                  = %s,\n",
    "                tags                    = %s,\n",
    "                inserted_at             = %s,\n",
    "                updated_at              = %s, \n",
    "                revenue                 = %s,\n",
    "                warehouse_info          = %s,\n",
    "                status_history          = %s,\n",
    "                partner                 = %s,\n",
    "                assigning_seller        = %s\n",
    "            WHERE id_column             = %s;\"\"\")\n",
    "    vars_to_update = (shop_id, id, status_name, status, tags, inserted_at,  updated_at, revenue, warehouse_info, status_history, \n",
    "                       partner, assigning_seller, id_column)\n",
    "    curr.execute(query, vars_to_update)\n",
    "\n",
    "\n",
    "def check_if_record_exists(curr, id_column): \n",
    "    query = (\"\"\"SELECT id_column FROM project_1_data WHERE id_column = %s\"\"\")\n",
    "\n",
    "    curr.execute(query, (id_column,))\n",
    "    return curr.fetchone() is not None\n",
    "\n",
    "\n",
    "def append_from_df_to_db(curr,df2):\n",
    "    for i, row in df2.iterrows():\n",
    "        insert_into_table(curr, row['shop_id'], row['id'], row['status_name'], row['status'], row['tags'], row['inserted_at'], row['id_column'], row['updated_at'], row['revenue'], row['warehouse_info'], row['status_history'], \n",
    "                          row[''], row['partner'], row['assigning_seller'])\n",
    "\n",
    "\n",
    "def update_db(curr,df2):\n",
    "    tmp_df = pd.DataFrame(columns=['shop_id', 'id', 'status_name', 'status', 'tags', 'inserted_at', 'id_column',  'updated_at', 'revenue',  'warehouse_info', 'status_history', \n",
    "                                    'partner', 'assigning_seller'])\n",
    "    for i, row in df2.iterrows():\n",
    "        if check_if_record_exists(curr, row['id_column']): \n",
    "            update_row(curr, row['shop_id'], row['id'], row['status_name'], row['status'], row['tags'], row['inserted_at'], row['id_column'],   row['updated_at'], row['revenue'],  row['warehouse_info'], row['status_history'], \n",
    "                        row['partner'], row['assigning_seller'])\n",
    "        else: \n",
    "            tmp_df = pd.concat([tmp_df, pd.DataFrame([row])])\n",
    "\n",
    "    return tmp_df\n",
    "\n",
    "#____________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "# Kết nối với database\n",
    "def connect_to_db(host_name, dbname, port, username, password):\n",
    "    try:\n",
    "        conn = ps.connect(host = host_name, database = dbname, \n",
    "               user = username, password = password, port = port)\n",
    "    except ps.OperationalError as e:\n",
    "        raise e\n",
    "    else:\n",
    "        print('Hurrayyyyyy! I am on the CLOUD!')\n",
    "        return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dad31b0-487d-4706-8cee-7f79912d53d2",
   "metadata": {},
   "source": [
    "# Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18187ad9-1786-4124-ab19-68be7639b2d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "host_name          = ''\n",
    "dbname             = ''\n",
    "port               = ''\n",
    "username           = ''\n",
    "password           = ''\n",
    "conn               = None\n",
    "\n",
    "conn = connect_to_db(host_name, dbname, port, username, password)\n",
    "curr = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef39296-db7f-4f48-b107-204ecccb22fd",
   "metadata": {},
   "source": [
    "# Divide data into small chunk, upload them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae1699-7939-4bf7-990d-01a1f5bb9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_chunk = len(df) / 100\n",
    "dfs = np.array_split(df, int(number_of_chunk) +1)\n",
    "\n",
    "# Edit (To assign a new col based on sequential number of df in dfs):\n",
    "\n",
    "print('- Number of pieces in df is: ' + str(len(dfs)))\n",
    "\n",
    "chunk_list_df = pd.read_csv(r'FILE', index_col=0) \n",
    "print('- Number of Chunk is: ' + str(len(chunk_list_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67913a-6e12-4fa4-8602-d3bed8c61df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(chunk_list_df) == 0:\n",
    "    print('Congratulation, sir!')\n",
    "else:\n",
    "    for i in chunk_list_df['Chunk']:\n",
    "        print('Uploading _ _ _ _ _ _ _ _ ' + str(chunk_list_df['Chunk'][i]))\n",
    "        new_vid_df = update_db(curr, dfs[i])\n",
    "        conn.commit()\n",
    "    \n",
    "        append_from_df_to_db(curr, new_vid_df)\n",
    "        conn.commit()\n",
    "    \n",
    "        print('Drop '+ str(chunk_list_df['Chunk'][i]))\n",
    "        chunk_list_df = chunk_list_df.drop(chunk_list_df['Chunk'][i])\n",
    "        chunk_list_df.to_csv(r'FILE')\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
